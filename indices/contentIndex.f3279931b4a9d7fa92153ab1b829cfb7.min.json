{"/":{"title":"Home","content":"\n## Hello! üëã\n\nMy name is Krystian Ko≈õcielniak.¬†I‚Äôm a proud husband and father to a sneaky toddler.\n\nI [write code](https://github.com/kkoscielniak)¬†for a living, currently at [Pickatale](https://pickatale.com/). Whenever I am not doing that or looking after my kiddo‚Äô, I [read](https://koscielniak.pro/books/books), play video games or try to make sample-based boombap beats.\n\n## What is this place?\n\nThis is my¬†_**digital garden**_, my own corner in the web for sharing what I learn in public.\n\nIt's pretty empty at the moment, as I am going through a bit of maintenance atm. \n\n## Wanna talk? \nJust drop me \u003ca href=\"mailto:krystiankoscielniak@proton.me\"\u003ean email\u003c/a\u003e, or DM me on [Insta](https://instagram.com/pankoscielniak). I don‚Äôt check LinkedIn a lot.","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/":{"title":"Software Development","content":"","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/":{"title":"Testing JavaScript","content":"Course notes I've taken during [Testing JavaScript](https://testingjavascript.com/) course by [Kent C. Dodds](https://kentcdodds.com/).\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/configuring-jest/":{"title":"Configuring Jest","content":"","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/configuring-jest/code-coverage-in-jest":{"title":"Code Coverage in Jest","content":"\nUse `jest --coverage` to generate coverage report after testing. The report in HTML will be saved in `./coverage` directory. This directory **should** be included in `.gitignore`.\n\nThe coverage report will include the _test utilities_ as well, which makes no sense and affects the stats. We only want to know how well tested the application code is.\n\nWe can add `collectCoverageFrom` to `jest.config.js`.\n\n```js\nmodule.exports = {\n  collectCoverageFrom: [\"**/src/**/*.js\"],\n};\n```\n\n\u003e [!tip] Jest is excluding `__tests__` by default\n\nThe coverage report is generated by `babel-plugin-istanbul` under the hood. It's possible to omit some parts in the coverage report with `/* istanbul ignore next */` directive. However this is not recommended, as it's a kind of _lying to yourself_ about how much of the code have been covered.\n\nIt's possible to set the `coverageThreshold` that will enforce how much of coverage is necessary for the code to pass the tests:\n\n```js\nmodule.exports = {\n  coverageThreshold: {\n    global: {\n      statements: 100,\n      branches: 100,\n      functions: 100,\n      lines: 100,\n    },\n  },\n};\n```\n\nIt's nice to set a bit below what the coverage is as of now, to make sure there won't be much of new code without tests committed.\n\n\u003e [!danger] The coverage is not a perfect metric for confidence.\n\u003e\n\u003e Not all lines in the codebase are _equal_ (some are more important than others).\n\nIt's possible to use a glob when setting the `coverageThreshold`.\n\n```js\nmodule.exports = {\n  coverageThreshold: {\n    \"./src/shared/utils.js\": {\n      statements: 100,\n      branches: 100,\n      functions: 100,\n      lines: 100,\n    },\n  },\n};\n```\n\n**Note:** When we add the specific files to the configuration, the `global` coverage threshold **lowers**.\n\nThe coverage can be added to CI/CD setup using [codecov](https://codecov.io).\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/configuring-jest/configuring-jest-for-testing-js-applications":{"title":"Configuring Jest for testing JS applications","content":"\n\u003e This note goes through useful Jests features, without actually going to how to write tests.\n\n## `process.env.NODE_ENV`\n\nFor testing `process.env.NODE_ENV === 'test'`. This can be used to enable `commonjs` modules in `babel` just for testing.\n\nJest picks up `.babelrc.js` automatically.\n\n## Configuring Jest's test environment for testing `node` or browser code\n\nJest uses JS DOM module to simulate browser in `node`. Technically the `window` property is simulated in `node` environment.\n\nWe can customize Jest to _enforce_ Browser/`node` environment with:\n\n```sh\njest -- --env=\"node\" // this will exclude JS DOM from the environment\n```\n\nIncluding JS DOM in the test runner without actually having a code that relies on the browser APIs may negatively affect the runners performance.\n\nThis can also be handled in `jest.config.js`:\n\n```js\nmodule.exports = {\n  testEnvironment: \"jest-environment-node\",\n  // testEnvironment: 'jest-environment-jsdom' // \u003c-- this works as well\n};\n```\n\nThese `testEnviroment`s are actually `node_modules`.\n\n## Support CSS imports with `moduleNameMapper`\n\nImporting styles is handled with `webpack` and `style-loader`, however this only works for the application itself. By default Jest will complain about importing CSS files, because it's not sure how to handle that imports.\n\nWhat we want to do is to _mock_ the non-JS module (CSS being one) with `moduleNameMapper` option:\n\n```js\n// jest.config.js\nmodule.exports = {\n  moduleNameMapper: {\n    \"\\\\.css$\": require.resolve(\"./test/style-mock.js\"),\n  },\n};\n\n// test/style-mock.js\nmodule.exports = {};\n```\n\n## Support Webpack CSS modules with `identity-obj-proxy`\n\nBy just mocking the styles module with `moduleNameMapper` may result in skipping the `className` property (or, to be precise, the `class` attr) in rendered component (`style-mock.js` is an empty object, so `styles.exampleStyle` is `undefined`.\n\nHowever, it may prove useful to add the `className` to the in-test rendered component for many purposes (eg handling the `classNames` logic).\n\nIf we‚Äôre using CSS modules with webpack, then we can improve our `moduleNameMapper` to include the css module property name in our tests using `identity-obj-proxy`:\n\n```js\n// jest.config.js\nmodule.exports = {\n  moduleNameMapper: {\n    \"\\\\.module.css$\": \"identity-obj-proxy\",\n  },\n};\n\n// test/style-mock.js\nmodule.exports = {};\n```\n\n`identity-obj-proxy` returns the path that was accessed to resolve a particular module.\n\n## Snapshot testing\n\nIf we'd like to test if the function returns a serializable value, we could just write:\n\n```js\nimport { getFlyingSuperHeros } from \"../super-heros\";\n\ntest(\"returns returns super heros that can fly\", () =\u003e {\n  const flyingHeros = getFlyingSuperHeros();\n  expect(flyingHeros).toEqual([\n    { name: \"Dynaguy\", powers: [\"disintegration ray\", \"fly\"] },\n    { name: \"Apogee\", powers: [\"gravity control\", \"fly\"] },\n  ]);\n});\n```\n\nHowever, at some point `flyingHeroes` might change, and when it'd happen, we'd need to figure out what changes in the object and to manually change the assertion in test case. This can be _semi-automated_ with _snapshot testing_:\n\n```js\nimport { getFlyingSuperHeros } from \"../super-heros\";\n\ntest(\"returns returns super heros that can fly\", () =\u003e {\n  const flyingHeros = getFlyingSuperHeros();\n  expect(flyingHeros).toMatchSnapshot();\n});\n```\n\nThis will make Jest to create a `\u003ctest-filename\u003e.js.snap` file in which the most recent snapshot will live.\n\nIf the snapshot test fails (because the tested object was changed), we can update the snapshot with `jest -u` (_update_).\n\nWe may also use `toMatchInlineSnapshot` - in this case, the snapshot won't live in a separate file. Jest will pass the snapshot to the test file itself. Using `-u` flag will update the test file assertion.\n\nThis also works with serializing and snapshotting the DOM nodes. In such case it's great to use Prettier, to make sure the real HTML and snapshot HTML are formatted in the same manner.\n\n## Custom Jest Snapshot Serializers\n\nIf we're using some custom UI Library, like `emotion`, we may see strange classes in our snapshots. It'd be more clear to see the clear CSS, instead of weird class names.\n\nThe general rule is to use custom Jest Snapshot Serializer.\n\nFor Emotion, this can be done with `@emotion/jest`:\n\n```js\nmodule.exports = {\n  snapshotSerializers: [\"@emotion/jest/serializer\"],\n};\n```\n\n## Custom Module Resolution with `moduleDirectories`\n\nIf we use Webpack's `resolve.modules` configuration to make common utils accessible across the application without relative paths, we need to emulate similar behavior in Jest. To do that, we use `moduleDirectories` configuration option:\n\n```js\nmodule.exports = {\n  moduleDirectories: [\"node_modules\", path.join(__dirname, \"src\"), \"shared\"],\n};\n```\n\nThis will make Jest to look up the imported modules in `node_modules` and in `./shared`. No more relative paths.\n\n## Configuring Jest to run setup for all tests before actual testing\n\nTo take care of test boilerplate and establish a good testing environment for our tests, we use the `setupFilesAfterEnv` option, together with e.g. `@testing-library/jest-dom`.\n\n```js\n// jest.config.js\nmodule.exports = {\n  setupFilesAfterEnv: [\"@testing-library/jest-dom/extend-expect\"],\n};\n```\n\nNote: `@testing-library/jest-dom/extend-expect` is a _script_. It could be any other boilerplate setup script out there.\n\n## Watch Mode\n\nJust use `jest --watch`. Preferably in `npm` script (eg. `test:watch`).\n\nIt uses `git` working copy to determine what files have changed.\n\nInteractive Snapshots (`i`) are quite useful. It's also possible to filter by filename or test description (`p` and `t`).\n\n### `--watchAll`\n\n`jest --watchAll` will open `jest` in watch mode, but will run **all tests** every time any test file changes.\n\nIt's possible to make Jest to automatically run in watch mode in development environment and in _normal_ mode if it's in CI with `is-ci-cli` npm package:\n\n```json\n// package.json\n{\n  \"scripts\": {\n    \"test\": \"is-ci test:coverage test:watch\",\n    \"test:coverage\": \"...\",\n    \"test:watch\": \"...\"\n  }\n}\n```\n\n## Connecting Jest to Node.js Debugger/Chrome DevTools\n\nBy default using the `debugger` keyword won't do anything. To run tests with Node.js debugger, we need:\n\n```sh\nnode --inspect-brk \u003cpath_to_jest_binary\u003e --runInBand // inspect break\n```\n\n`--runInBand` makes sure `jest` will run only in one `node` process (`jest` is spawning processes by default to fasten things up, but it may be forced to use one process - helpful for tests debugging).\n\nThen we can connect the debugger with DevTools. The remote sessions available are from chrome://inspect/.\n\n\u003e [!tip] There also should be possible to use NodeJS button in DevTools upper left\n\n## Using different configuration files\n\nLet's say we have that set options differently (e.g. have different `testEnvironment`):\n\n- `jest.common.config.js`\n- `jest.server.config.js`\n- `jest.client.config.js`\n\nTo make sure the different configuration files target different test files, we can set `testMatch` option:\n\n```js\n// jest.server.config.js\nmodule.exports = {\n  // rootDir: \u003cif custom test file is not in `/`\u003e\n  testMatch: \"./__tests__server__/**/*.test.js\",\n};\n```\n\nThen we need to use `jest --config jest.server.config.js`\n\nThis method would need us to maintain lots of `npm scripts`, since it's not possible to run multiple `watch` sessions at once\n\nAllow to run multiple Jest configurations at once (and reduce the complexity of `npm scripts` by the way).\n\n```js\nmodule.exports = {\n  ...require(\"./jest.common.config.js\"),\n  /* ... */\n  projects: [\"./jest.client.js\", \"./jest.server.js\"],\n};\n```\n\n\u003e [!tip] The _project_ configurations can use `displayName` option to differentiate the output.\n\n### Checking out the configuration\n\nTo display the whole resolved configuration use `jest --config`. The `globalConfig` states the configuration in the root `jest.config.js` file. It'll list also other options that **should be** configured in root config.\n\n## Run ESLint with Jest\n\nIt's possible to change the `runner` which Jest will use - by default it uses `jest-runner`, but we can use e.g. `jest-runner-eslint` to lint the code that'll run `eslint` during evaluation of the project state through `yarn test`.\n\nThis may prove useful when it comes to organize the toolkit around the project especially when it comes to bigger, legacy projects (e.g. ones that weren't linted before, and we want to lint only the code that we changed - improving the code quality gradually).\n\n## Test specific projects in Watch Mode\n\nWith `jest-watch-select-projects` plugin it's possible to specify which projects should be tested in `jest --watch`, similarly to how we select files for current tests run.\n\n```js\nmodule.exports: {\n    watchPlugins: ['jest-watch-select-projects']\n}\n```\n\n## Filtering tests ran with Typeahead support\n\n\u003e [!tip] Typeahead is similar of Intellisense, but non-proprietary\n\nThanks to `jest-watch-typeahead` plugins it's possible to add patternmatching to the tests filtering:\n\n```js\nmodule.exports: {\n    watchPlugins: ['jest-watch-typeahead/filename', 'jest-watch-typeahead/testname']\n}\n```\n\n## Run only relevant tests on Git commit hook\n\n`husky` and `lint-staged` allow to configure the git hook to run tests only\n\n```json\n// package.json\n{\n  \"husky\": {\n    \"hooks\": {\n      \"pre-commit\": \"lint-staged \u0026\u0026 ...\"\n    }\n  },\n  \"lint-staged\": {\n    \"**/*.+(js|json|css|html|md)\": [\n      \"prettier\",\n      \"jest --findRelatedTests\", // \u003c-- This\n      \"git add\"\n    ]\n  }\n}\n```\n\n`jest --findRelatedTests` will find tests that are related to the files defined in `lint-staged`.\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/":{"title":"Testing with Cypress","content":"","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/configuring-cypress":{"title":"Fundamentals of testing with Cypress and Testing Library","content":"Cypress is a tool for E2E testing.\n\nInternally Cypress is an application that runs natively on the computer, but is installed via `npm`/`yarn`.\n\nTo open Cypress application we use `cypress open`. We don't need the application to run tests, we can default to running them in CLI (headless mode), via `cypress run`. \n\n## Configuring Cypress\n```json\n// cypress.json\n{\n  \"baseUrl\": \"http://localhost:8080\",\n  \"integrationFolder\": \"cypress/e2e\", // where the test files lie\n  \"viewportHeight\": 900,\n  \"viewportWidth\": 400\n}\n```\n\n\u003e [!tip] The configuration can be viewed from `cypress open`\n\u003e \n\u003e Check out the settings tab to see what options were set and where exactly (`cypress.json`, ENV etc.)\n### Enabling `cypress` in `eslint`\n```tsx\nmodule.exports = {\n/* [...] */\nroot: true,\n  plugins: ['eslint-plugin-cypress'],\n  extends: ['plugin:cypress/recommended'],\n  env: {'cypress/globals': true},\n  /* [...] */\n}\n\n```\n\n\nIt's also useful to add `cypress/videos` and `cypress/screenshots` to `.gitignore`. \n\n## Installing Cypress Testing Library\n```\nyarn add -D @testing-library/cypress\n```\n\n```tsx\n// cypress/support/index.js\n\nimport '@testing-library/cypress/add-commands'\n/* [...] */\n```\nThis adds `findBy`/`getBy`... methods to `cy` object. \n\n## Scripting Cypruss for local development and CI\nBy default we need to run the application in the background for the tests to run. Also, we want to default to `cypress run` for CI.\n\nFor that kind of setup we can use `start-server-and-test` package. `is-ci-cli` package is also useful for determining in which environment we want to run `cypress`. \n\n```json\n{\n  /* [...] */\n  \"scripts\": {\n    \"cy:run\": \"cypress run\",\n    \"cy:open\": \"cypress open\",\n    \"test:e2e\": \"is-ci \\\"test:e2e:run\\\" \\\"test:e2e:dev\\\"\",\n    \"pretest:e2e:run\": \"npm run build\",\n    \"test:e2e:run\": \"start-server-and-test start http://localhost:8080 cy:run\",\n    \"test:e2e:dev\": \"start-server-and-test dev http://localhost:8080 cy:open\",\n    /* [...] */\n    \n    \"dev\": \"/* [...] */\",\n    \"start\": \"/* [...] */\",\n    \"setup\": \"npm install\",\n    /* [...] */\n  },\n}\n```\n\n\u003e [!tip] Btw, `npm` has `pre\u003cscripts\u003e` üëå\n\u003e \n\u003e Every script named `pre\u003cother-script\u003e` where `other-script` is an existing `npm` script will run **before** that `other-script`.\n\nWe could set up `husky:precommit` to run E2E tests, but as the project grows, the tests would need lot of time to go through the tests, so it's better to rely on CI for these. \n\n```yml\n# .travis.yml\n\n# [...]\naddons:\n  apt:\n    packages:\n      - libgconf-2-4\ncache:\n  directories:\n    - ~/.npm\n    - ~/.cache\nscript: npm run setup\n```","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/custom-cypress-cmds":{"title":"Custom Cypress commands","content":"We can append commands to `cy` object with usage of _custom commands_. This can be used for making reusable assertions, making HTTP requests directly etc.: \n\n```ts\n// cypress/support/commands.js\nCypress.Commands.add('createUser', overrides =\u003e {\n  const user = userBuilder(overrides)\n  return cy\n    .request({\n      url: 'http://localhost:3000/register',\n      method: 'POST',\n      body: user,\n    })\n    .then(({body}) =\u003e body.user)\n})\nCypress.Commands.add('assertHome', () =\u003e {\n  cy.url().should('eq', `${Cypress.config().baseUrl}/`)\n})\n\nCypress.Commands.add('assertLoggedInAs', user =\u003e {\n  cy.window().its('localStorage.token').should('be.a', 'string')\n  cy.findByTestId('username-display').should('have.text', user.username)\n})\n```\n\nAfter that we can use `cy.createUser()`, `cy.assertHome()` and `cy.assertLoggedInAs()` to call them. \n\nWe can use `overrides` to override the default configuration. \n\n## Command `subject`\nIf the command returns anything, we can get to this returned value in this way: \n```ts\ncy.createUser().then(user =\u003e /* [...] */)\n```","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/cy-request-fn":{"title":"cy.request fn","content":"\nWe can use `cy.request(req)` to make HTTP calls directly from Cypress. \n```ts\ncy.request({\n    url: 'http://localhost:3000/register',\n    method: 'POST',\n    body: user,\n});\n```\n\nThese requests are usually reusable and can be used as [[development/testing-javascript/cypress/custom-cypress-cmds]]. \n\nTypically, `cy.request`s are faster than calling HTTP from within the tested app. ","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/debugging-tests":{"title":"Debugging tests in Cypress","content":"To debug the test, we can use this `Promise` like syntax: \n```tsx\ndescribe('anonymous calculator', () =\u003e {\n  it('can make calculations', () =\u003e {\n    /* [...] */\n    cy.findByText(/^\\+$/).then(subject =\u003e {\n        debugger; \n        return subject;\n    })\n    // .pause()\n    .click()\n    \n    /* [...] */\n  })\n})\n```\n\nIf we call the `debugger` and have Dev Tools in Cypress opened, the test will pause and we're be redirected to Source tab in Dev Tools. \n\nWe also want to return the `subject` to maintain it through the chain of interactions.\n\n`subject` is a jQuery node, btw. \n\nWe can also use `.pause()` to pause the execution without moving us to Dev Tools debugger. To resume the test, press ‚èØÔ∏è in Cypress window.\n\n`console.log`s go to Cypresses Dev Tools. \n\nWe could also mess with the Component code as well, as Cypress injects itself into `window`: \n```tsx\nfunction Calculator () {\nconst [theme, setTheme] = useState();\n    if (window.Cypress) {\n        window.setTheme = setTheme\n    }\n}\n```\n\n\u003e [!danger] We need to keep in mind we want the tests to resemble **how the user would interact with the component**\n\u003e \n\u003e Probably the user won't use `window.setTheme` on his own. But this can help develop tests in the first place. \n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/first-cypress-test":{"title":"First test in Cypress","content":"\u003e [!tip] Keep in mind the tested application needs to be running in the background\n\n```tsx\ndescribe('anonymous calculator', () =\u003e {\n  it('can make calculations', () =\u003e {\n    cy.visit('/')\n    cy.findByText(/^1$/).click()\n    cy.findByText(/^\\+$/).click()\n    cy.findByText(/^2$/).click()\n    cy.findByText(/^=$/).click()\n    cy.findByTestId('total').should('have.text', '3')\n  })\n})\n```\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/install-react-dev-tools":{"title":"Install React Dev Tools in Cypress","content":"If we run Cypress in Chrome-based browser that has the React Dev Tools extension installed, we still need to register the tested app in DevTools.\n\nIn our app: \n```ts\n// src/react-devtools-hook.js\n\nif (window.Cypress) {\nwindow.__REACT_DEVTOOLS_GLOBAL_HOOK__ =\n  window.parent.__REACT_DEVTOOLS_GLOBAL_HOOK__\n}\n```\n\n```ts\n// src/index.js\n\nimport './react-devtools-hook'; // in the first line! \n/* [...] */\n\n```","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/testing-login-flow":{"title":"Testing login flow in Cypress","content":"The simplest form of testing the login flow would be to make Cypress register, login and logout several times: \n\n```ts\n\nimport {userBuilder} from '../support/generate'\ndescribe('login', () =\u003e {\n  it('should login an existing user', () =\u003e {\n    const user = userBuilder()\n\n    cy.visit('/')\n    cy.findByText(/register/i).click()\n    cy.findByLabelText(/username/i).type(user.username)\n    cy.findByLabelText(/password/i).type(user.password)\n    cy.findByText(/submit/i).click()\n    cy.findByText(/login/i).click()\n    cy.findByLabelText(/username/i).type(user.username)\n    cy.findByLabelText(/password/i).type(user.password)\n    cy.findByText(/submit/i).click()\n    cy.findByText(/logout/i).click()\n  })\n})\n```\n\nBut we are a bit of overtesting here. We have a very similar flow to the one presented in [[development/testing-javascript/cypress/testing-registration-flow]]. If there would be an error, we'd have it visible in many test cases, which might obscure where the issue really occures. Also, it makes Cypress to run longer. \n\nWe can make Cypress to handle the `/login` request for us with [[development/testing-javascript/cypress/cy-request-fn]] as a [[development/testing-javascript/cypress/custom-cypress-cmds|custom command]]. \n\n```ts\ndescribe('login', () =\u003e {\n  it('should login an existing user', () =\u003e {\n    cy.createUser().then(user =\u003e {\n      cy.visit('/')\n      cy.findByText(/login/i).click()\n      cy.findByLabelText(/username/i).type(user.username)\n      cy.findByLabelText(/password/i).type(user.password)\n      cy.findByText(/submit/i).click()\n      cy.findByText(/logout/i).click()\n      cy.findByText(/login/i).click()\n      cy.findByLabelText(/username/i).type(user.username)\n      cy.findByLabelText(/password/i).type(user.password)\n      cy.findByText(/submit/i).click()\n      cy.findByText(/logout/i).click()\n    })\n  })\n})\n\n```\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/cypress/testing-registration-flow":{"title":"Testing registration flow in Cypress","content":"\nWith E2E testing, there might be a situation we want to test a form by providing some data. However, the data we provided may already exist in the database.\n\nWe could cleanup the DB for testing before each test, but this may be troublesome (or even not possible at all). \n\nWe can create the `userBuilder()` fn in `support/generate.ts` that uses `test-data-bot`:\n\n```ts\n// support/generate.ts\nimport {build, fake} from 'test-data-bot'\n\nconst userBuilder = build('User').fields({\n  username: fake(f =\u003e f.internet.userName()),\n  password: fake(f =\u003e f.internet.password()),\n})\n\nexport {userBuilder}\n\n```\n\n```ts\n// cypress/e2e/register.ts\nimport {userBuilder} from '../support/generate'\n\ndescribe('registration', () =\u003e {\n  it('should register a new user', () =\u003e {\n      // given\n    const user = userBuilder()\n// when\n    cy.visit('/')\n    cy.findByText(/register/i).click()\n    cy.findByLabelText(/username/i).type(user.username)\n    cy.findByLabelText(/password/i).type(user.password)\n    cy.findByText(/submit/i).click()\n// then\n    cy.url().should('eq', `${Cypress.config().baseUrl}/`)\n    cy.window().its('localStorage.token').should('be.a', 'string')\n    cy.findByTestId('username-display').should('have.text', user.username)\n  })\n})\n\n```\n\n## Simulate HTTP errors in Cypress\nWe need to intercept HTTP request in Cypress with `cy.server()` and `cy.route()`. \n\n```ts\nit(`should show an error message if there's an error registering`, () =\u003e {\n    cy.server()\n    cy.route({\n      method: 'POST',\n      url: 'http://localhost:3000/register',\n      status: 500,\n      response: {},\n    })\n    cy.visit('/register')\n    cy.findByText(/submit/i).click()\n    cy.findByText(/error.*try again/i)\n  })\n```","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/fundamentals/":{"title":"Testing Fundamentals","content":"","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/fundamentals/dom-testing-library":{"title":"DOM Testing Library","content":"\nDOM Testing Library is the simplest, yet complete testing utility. It's a part of [`@testing-library`](https://testing-library.com/docs/) family.\n\nIt's possible to use **DOM Testing Library** to test in virtually any JS framework out there (yep, even jQuery), however it's not that much practical.","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/fundamentals/pyramid-of-testing":{"title":"Pyramid of Testing","content":"- [[development/testing-javascript/static-analysis|Static analysis]]\n    - type errors and typs\n- [[development/testing-javascript/jest/_index|Unit tests]]\n    - verifying that isolated parts of the system work as expected\n- [[development/testing-javascript/jest/integration-tests-using-rtl|Integration tests]]\n    - verifying that several units work as intended when connected\n- [[development/testing-javascript/cypress/_index|E2E]] (functional tests)\n    - army of robots that clicks around the app and verifies that the app works correctly as a whole system","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/fundamentals/simple-testing-framework":{"title":"Simple testing framework in JS","content":"Here's an example of how the simple, `jest`-like testing framework would look like. \n\n## The simplest test\n\nThe automated test in JS is a code that throws an `Error` if the assumption does not match the result (the result is **unexpected**).\n\nThe simplest form of the passing test:\n\n```js\nconst { sum, subtract } = require(\"./math\");\nlet result, expected;\n\nresult = sum(3, 7);\nexpected = 10;\nif (result !== expected) {\n  throw new Error(`${result} is not equal to ${expected}`);\n}\n\nresult = subtract(7, 3);\nexpected = 4;\nif (result !== expected) {\n  throw new Error(`${result} is not equal to ${expected}`);\n}\n```\n\nTo write the **_test_**, we need to write a code that throws an `Error` with a **useful message** to understand what's wrong with our code.\n\nIt is relatively easy and reliable to test pure functions this way.\n\nThe error thrown can be abstracted into a function taking `actual` as a parameter and returning `toBe(expected)` fn.\n\n```ts\nfunction sum(a: number, b: number): number {\n  return a - b; // This fn is broken\n}\n\nfunction expect(actual: any) {\n  return {\n    toBe(expected: any) {\n      if (actual !== expected) {\n        throw new Error(`${actual} is not equal to ${expected}`);\n      }\n    },\n    toEqual(expected: any) {\n      /* ...*/\n    },\n    toBeGreatherThan(expected: any) {\n      /* ...*/\n    },\n    // etc.\n  };\n}\n\nexpect(sum(3, 7)).toBe(10);\n```\n\n## Encapsulating the tests into simple _framework_\n\nIn the simple case above, once any of the tests fails, the subsequent ones won't run. In addition of that, the stacktrace would display that the **`Error` occured in the same line it was thrown** (`:9`), whereas we'd like to see the broken sum fn as the reason for failing test (without digging through the stacktrace).\n\nThat's why we should encapsulate and isolate tests:\n\n```ts\nfunction sum(a: number, b: number): number {\n  return a - b; // This fn is broken\n}\n\nfunction subtract(a: number, b: number): number {\n  return a - b;\n}\n\nfunction expect(actual) {\n  return {\n    toBe(expected) {\n      if (actual !== expected) {\n        throw new Error(`${actual} is not equal to ${expected}`);\n      }\n    },\n  };\n}\n\nfunction test(title, callback) {\n  try {\n    callback();\n    console.log(`[ok] ${title}`);\n  } catch (error) {\n    console.error(`[not ok] ${title}`);\n    console.error(error);\n  }\n}\n\ntest(\"sum adds numbers\", () =\u003e {\n  const result = sum(3, 7);\n  expect(result).toBe(10);\n});\n\ntest(\"subtract subtracts numbers\", () =\u003e {\n  const result = subtract(7, 3);\n  expect(result).toBe(4);\n});\n```\n\nTo sum up, the test should allow the developer to **quickly find what's broken**, without having to delve into the stack trace and else.\n\n## Adding a way of testing `async` code\n\nSimple adding `async` to the `callback()` fns and `await`ing for the result would cause the tests to falsely pass and to throw an `UnhandledPromiseRejection` `Error` with the reason of rejection (being our actual broken `sum` fn).\n\n```sh\n$ ts-node test.ts\n[ok] sum adds numbers\n[ok] subtract subtracts numbers\n\nthrow new Error (${actual} is not equal to ${expected});\nError: -4 is not equal to 10\nat [...]\n```\n\nThis is due to the fact that `async () =\u003e { /* test case */ }` returns a `Promise`. The `Error` thrown by the broken `sum()` in the test case causes **rejection of that `Promise`**. The `callback()` call inside `test()` returns that `Promise` without passing the error down. That's why we need to add `async/await` clauses to the `test` fn itself.\n\n```ts\nasync function test(title: string, callback: () =\u003e any) {\n  try {\n    await callback();\n    console.log(`[ok] ${title}`);\n  } catch (error) {\n    console.error(`[not ok] ${title}`);\n    console.error(error);\n  }\n}\n\ntest(\"sum adds numbers\", async () =\u003e {\n  const result = await sum(3, 7);\n  const expected = 10;\n  expect(result).toBe(expected);\n});\n```\n\n## Making test fns global\n\nWe want the test fns to be accessible in different `*.test.ts` files. However, we don't want to have to import the fns in each of test file (many testing frameworks seem to _embrace_ the global functions).\n\nTo make them so we can create a `setup-globals.ts` with the `test` and `expect` fns torn out...\n\n```ts\n// setup-globals.ts\nfunction expect(actual: any) {\n  return {\n    toBe(expected: any) {\n      if (actual !== expected) {\n        throw new Error(`${actual} is not equal to ${expected}`);\n      }\n    },\n  };\n}\n\nasync function test(title: string, callback: () =\u003e any) {\n  try {\n    await callback();\n    console.log(`[ok] ${title}`);\n  } catch (error) {\n    console.error(`[not ok] ${title}`);\n    console.error(error);\n  }\n}\n\nglobal.expect = expect;\nglobal.test = test;\n```\n\n```ts\n// test.ts\nfunction sum(a: number, b: number): number {\n  return a - b;\n}\n\nfunction subtract(a: number, b: number): number {\n  return a - b;\n}\n\ntest(\"sum adds numbers\", async () =\u003e {\n  const result = await sum(3, 7);\n  const expected = 10;\n  expect(result).toBe(expected);\n});\n\ntest(\"subtract subtracts numbers\", () =\u003e {\n  const result = subtract(7, 3);\n  const expected = 4;\n  expect(result).toBe(expected);\n});\n```\n\n...and run the tests in this manner:\n\n```sh\n$ ts-node --require ./setup-globals.ts test.ts\n```\n\nThat being said, we've just created micro, `jest`-like testing framework.\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/":{"title":"Testing with Jest","content":"","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/fake-data":{"title":"Using fake data in tests","content":"It's actually better to generate data for tests than hardcoding it. The data itself is not important, so it doesn't matter if the hardcoded string is `Test title` from the tests standpoint. This bloats the test cases and may hint that the string is important, even if it isn't.\n\n\u003e [!tip] We need to know what we want to _communicate_ with our tests.\n\nThanks to `test-data-bot` library it's possible to _fake_ the data.\n\n```tsx\nimport * as React from \"react\";\nimport { render, screen, waitFor } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { build, fake, sequence } from \"test-data-bot\";\nimport { savePost as mockSavePost } from \"../api\";\nimport { Editor } from \"../post-editor\";\n\nconst postBuilder = build(\"Post\").fields({\n  title: fake((f) =\u003e f.lorem.words()),\n  content: fake((f) =\u003e f.lorem.paragraphs().replace(/\\r/g, \"\")),\n  tags: fake((f) =\u003e [f.lorem.word(), f.lorem.word(), f.lorem.word()]),\n});\n\nconst userBuilder = build(\"User\").fields({\n  id: sequence((s) =\u003e `user-${s}`),\n});\n\ntest(\"renders a form with title, content, tags, and a submit button\", async () =\u003e {\n  /* [...] */\n  const fakeUser = userBuilder();\n  const fakePost = postBuilder();\n  render(\u003cEditor user={fakeUser} /\u003e);\n\n  screen.getByLabelText(/title/i).value = fakePost.title;\n  screen.getByLabelText(/content/i).value = fakePost.content;\n  screen.getByLabelText(/tags/i).value = fakePost.tags.join(\", \");\n  const submitButton = screen.getByText(/submit/i);\n  userEvent.click(submitButton);\n\n  expect(mockSavePost).toHaveBeenCalledWith({\n    ...fakePost,\n    date: expect.any(String),\n    authorId: fakeUser.id,\n  });\n  /* [...] */\n});\n```\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/integration-tests-using-rtl":{"title":"Integration tests using Testing Library","content":"\nThe idea of integration test is to test an entire page, or maybe even an entire app by writing tests that navigate around the app as the normal user would.\n\nLet's assume we have a multi-form application like that:\n\n```js\n// app.js\nimport React, { createContext, useContext, useReducer, useState } from \"react\";\nimport { BrowserRouter as Router, Route, Link, Switch } from \"react-router-dom\";\nimport { submitForm } from \"./api\";\n\nconst MultiPageForm = createContext();\n\nfunction MultiPageFormProvider({ initialValues = {}, ...props }) {\n  const [initState] = useState(initialValues);\n  const [form, setFormValues] = useReducer(\n    (s, a) =\u003e ({ ...s, ...a }),\n    initState,\n  );\n  const resetForm = () =\u003e setFormValues(initialValues);\n  return (\n    \u003cMultiPageForm.Provider\n      value={{ form, setFormValues, resetForm }}\n      {...props}\n    /\u003e\n  );\n}\n\nfunction useMultiPageForm() {\n  const context = useContext(MultiPageForm);\n  if (!context) {\n    throw new Error(\n      \"useMultiPageForm must be used within a MultiPageFormProvider\",\n    );\n  }\n  return context;\n}\n\nfunction Main() {\n  return (\n    \u003c\u003e\n      \u003ch1\u003eWelcome home\u003c/h1\u003e\n      \u003cLink to=\"/page-1\"\u003eFill out the form\u003c/Link\u003e\n    \u003c/\u003e\n  );\n}\n\nfunction Page1({ history }) {\n  const { form, setFormValues } = useMultiPageForm();\n  return (\n    \u003c\u003e\n      \u003ch2\u003ePage 1\u003c/h2\u003e\n      \u003cform\n        onSubmit={(e) =\u003e {\n          e.preventDefault();\n          history.push(\"/page-2\");\n        }}\n      \u003e\n        \u003clabel htmlFor=\"food\"\u003eFavorite Food\u003c/label\u003e\n        \u003cinput\n          id=\"food\"\n          value={form.food}\n          onChange={(e) =\u003e setFormValues({ food: e.target.value })}\n        /\u003e\n      \u003c/form\u003e\n      \u003cLink to=\"/\"\u003eGo Home\u003c/Link\u003e | \u003cLink to=\"/page-2\"\u003eNext\u003c/Link\u003e\n    \u003c/\u003e\n  );\n}\n\nfunction Page2({ history }) {\n  const { form, setFormValues } = useMultiPageForm();\n  return (\n    \u003c\u003e\n      \u003ch2\u003ePage 2\u003c/h2\u003e\n      \u003cform\n        onSubmit={(e) =\u003e {\n          e.preventDefault();\n          history.push(\"/confirm\");\n        }}\n      \u003e\n        \u003clabel htmlFor=\"drink\"\u003eFavorite Drink\u003c/label\u003e\n        \u003cinput\n          id=\"drink\"\n          value={form.drink}\n          onChange={(e) =\u003e setFormValues({ drink: e.target.value })}\n        /\u003e\n      \u003c/form\u003e\n      \u003cLink to=\"/page-1\"\u003eGo Back\u003c/Link\u003e | \u003cLink to=\"/confirm\"\u003eReview\u003c/Link\u003e\n    \u003c/\u003e\n  );\n}\n\nfunction Confirm({ history }) {\n  const { form, resetForm } = useMultiPageForm();\n  function handleConfirmClick() {\n    submitForm(form).then(\n      () =\u003e {\n        resetForm();\n        history.push(\"/success\");\n      },\n      (error) =\u003e {\n        history.push(\"/error\", { error });\n      },\n    );\n  }\n  return (\n    \u003c\u003e\n      \u003ch2\u003eConfirm\u003c/h2\u003e\n      \u003cdiv\u003e\n        \u003cstrong\u003ePlease confirm your choices\u003c/strong\u003e\n      \u003c/div\u003e\n      \u003cdiv\u003e\n        \u003cstrong id=\"food-label\"\u003eFavorite Food\u003c/strong\u003e:{\" \"}\n        \u003cspan aria-labelledby=\"food-label\"\u003e{form.food}\u003c/span\u003e\n      \u003c/div\u003e\n      \u003cdiv\u003e\n        \u003cstrong id=\"drink-label\"\u003eFavorite Drink\u003c/strong\u003e:{\" \"}\n        \u003cspan aria-labelledby=\"drink-label\"\u003e{form.drink}\u003c/span\u003e\n      \u003c/div\u003e\n      \u003cLink to=\"/page-2\"\u003eGo Back\u003c/Link\u003e |{\" \"}\n      \u003cbutton onClick={handleConfirmClick}\u003eConfirm\u003c/button\u003e\n    \u003c/\u003e\n  );\n}\n\nfunction Success() {\n  return (\n    \u003c\u003e\n      \u003ch2\u003eCongrats. You did it.\u003c/h2\u003e\n      \u003cdiv\u003e\n        \u003cLink to=\"/\"\u003eGo home\u003c/Link\u003e\n      \u003c/div\u003e\n    \u003c/\u003e\n  );\n}\n\nfunction Error({\n  location: {\n    state: { error },\n  },\n}) {\n  return (\n    \u003c\u003e\n      \u003cdiv\u003eOh no. There was an error.\u003c/div\u003e\n      \u003cpre\u003e{error.message}\u003c/pre\u003e\n      \u003cLink to=\"/\"\u003eGo Home\u003c/Link\u003e\n      \u003cLink to=\"/confirm\"\u003eTry again\u003c/Link\u003e\n    \u003c/\u003e\n  );\n}\n\nfunction App() {\n  return (\n    \u003cMultiPageFormProvider initialValues={{ food: \"\", drink: \"\" }}\u003e\n      \u003cRouter\u003e\n        \u003cSwitch\u003e\n          \u003cRoute path=\"/page-1\" component={Page1} /\u003e\n          \u003cRoute path=\"/page-2\" component={Page2} /\u003e\n          \u003cRoute path=\"/confirm\" component={Confirm} /\u003e\n          \u003cRoute path=\"/success\" component={Success} /\u003e\n          \u003cRoute path=\"/error\" component={Error} /\u003e\n          \u003cRoute component={Main} /\u003e\n        \u003c/Switch\u003e\n      \u003c/Router\u003e\n    \u003c/MultiPageFormProvider\u003e\n  );\n}\n\nexport default App;\n```\n\n## Testing the user flow\n\n```tsx\nimport * as React from \"react\";\nimport { render, screen } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { submitForm } from \"../api\";\nimport App from \"../app-reach-router\";\n\njest.mock(\"../api\");\n\ntest(\"Can fill out a form across multiple pages\", async () =\u003e {\n  submitForm.mockResolvedValueOnce({ success: true });\n\n  const testData = { food: \"test food\", drink: \"test drink\" };\n  render(\u003cApp /\u003e);\n\n  userEvent.click(await screen.findByText(/fill.*form/i));\n\n  userEvent.type(await screen.findByLabelText(/food/i), testData.food);\n  userEvent.click(await screen.findByText(/next/i));\n\n  userEvent.type(await screen.findByLabelText(/drink/i), testData.drink);\n  userEvent.click(await screen.findByText(/review/i));\n\n  expect(await screen.findByLabelText(/food/i)).toHaveTextContent(\n    testData.food,\n  );\n  expect(await screen.findByLabelText(/drink/i)).toHaveTextContent(\n    testData.drink,\n  );\n\n  userEvent.click(await screen.findByText(/confirm/i, { selector: \"button\" }));\n\n  expect(submitForm).toHaveBeenCalledWith(testData);\n  expect(submitForm).toHaveBeenCalledTimes(1);\n\n  userEvent.click(await screen.findByText(/home/i));\n\n  expect(await screen.findByText(/welcome home/i)).toBeInTheDocument();\n});\n```\n\nWe're using `await screen.findBy...(...)` instead of `screen.getBy...(...)` because they wait for the transition between pages to be done (until the timeout exceeds).\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/tdd-with-ui-in-testing-library":{"title":"TDD with UI in React Testing Library","content":"\nNormally using TDD with UI is really difficult because testing utilities for UI often tie your tests closely to the implementation. However, Testing Library allows to work in TDD methodology.","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/testing-components":{"title":"Testing components with Jest and React Testing Library","content":"\n## New ways of using `@testing-library/react`\n\n- Don't return `getBy...` methods from `render(\u003cComponent /\u003e`. Use `screen` export instead\n- `userEvent` is better than `fireEvent`\n- Use `waitFor` instead of `wait`. They are _same_ but `waitFor` offers more possibilities\n\n## Using `jest-dom`\n\n`jest-dom` provides really useful extensions to jest‚Äôs built-in assertion library that will make it easier for us to write our test assertions (like `toHaveTextContent`).\n\n```ts\nimport * as React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"@testing-library/jest-dom\";\nimport { FavoriteNumber } from \"../favorite-number\";\n\ntest('renders a number input with a label \"Favorite Number\"', () =\u003e {\n  const div = document.createElement(\"div\");\n  ReactDOM.render(\u003cFavoriteNumber /\u003e, div);\n  expect(div.querySelector(\"input\")).toHaveAttribute(\"type\", \"number\");\n  expect(div.querySelector(\"label\")).toHaveTextContent(\"Favorite Number\");\n});\n```\n\n\u003e [!tip] KCD configured the test files to import `@testing-library/*` automatically\n\u003e\n\u003e That's why that import is missing from the examples\n\n## Using DOM Testing Library to write more maintainable tests\n\n```tsx\nimport * as React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport { getQueriesForElement } from \"@testing-library/dom\";\nimport { FavoriteNumber } from \"../favorite-number\";\n\ntest('renders a number input with a label \"Favorite Number\"', () =\u003e {\n  const div = document.createElement(\"div\");\n  ReactDOM.render(\u003cFavoriteNumber /\u003e, div);\n  const { getByLabelText } = getQueriesForElement(div);\n  const input = getByLabelText(/favorite number/i); // /i -\u003e case insensitive\n  expect(input).toHaveAttribute(\"type\", \"number\");\n});\n```\n\n## Using `@testing-library/react` for rendering\n\n```tsx\nimport * as React from \"react\";\nimport { render, screen } from \"@testing-library/react\";\nimport { FavoriteNumber } from \"../favorite-number\";\n\ntest('renders a number input with a label \"Favorite Number\"', () =\u003e {\n  render(\u003cFavoriteNumber /\u003e);\n  const input = screen.getByLabelText(/favorite number/i);\n  expect(input).toHaveAttribute(\"type\", \"number\");\n});\n```\n\n## React Testing Library's `debug` fn\n\n`debug(renderedComponent = null)` will `console.log` the HTML code for all rendered components (unless one is provided as an argument).\n\n```tsx\nimport * as React from \"react\";\nimport { render, screen } from \"@testing-library/react\";\nimport { FavoriteNumber } from \"../favorite-number\";\n\ntest('renders a number input with a label \"Favorite Number\"', () =\u003e {\n  render(\u003cFavoriteNumber /\u003e);\n  const input = screen.getByLabelText(/favorite number/i);\n  expect(input).toHaveAttribute(\"type\", \"number\");\n  screen.debug(); // \u003c-- w/o arg\n  // screen.debug(input); // \u003c-- with arg\n});\n```\n\n## Testing Event Handlers with `userEvent`\n\n`userEvent` fn more closely resebles the way the users interact with tested components than `fireEvent` itself.\n\n`userEvent.type` internally fires a bunch of `fireEvent`s to mimic human behavior. It follows `async/await` pattern.\n\n```tsx\nimport * as React from \"react\";\nimport { render, screen, fireEvent } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { FavoriteNumber } from \"../favorite-number\";\n\ntest(\"entering an invalid value shows an error message\", async () =\u003e {\n  render(\u003cFavoriteNumber /\u003e);\n  const input = screen.getByLabelText(/favorite number/i);\n  // fireEvent.change(input, {target: {value: '10'}})\n  await userEvent.type(input, \"10\");\n\n  // `FavoriteNumber` contains a `div` with `role=\"alert\"` defined for accessibility purposes\n  expect(screen.getByRole(\"alert\")).toHaveTextContent(/the number is invalid/i);\n});\n```\n\n## Test props updates\n\n```tsx\nimport * as React from \"react\";\nimport user from \"@testing-library/user-event\";\nimport { render, screen } from \"@testing-library/react\";\nimport { FavoriteNumber } from \"../favorite-number\";\n\ntest(\"entering an invalid value shows an error message\", async () =\u003e {\n  const { rerender } = render(\u003cFavoriteNumber /\u003e);\n  const input = screen.getByLabelText(/favorite number/i);\n  await user.type(input, \"10\");\n  expect(screen.getByRole(\"alert\")).toHaveTextContent(/the number is invalid/i);\n  rerender(\u003cFavoriteNumber max={10} /\u003e);\n  expect(screen.queryByRole(\"alert\")).not.toBeInTheDocument();\n});\n```\n\n### The difference between `getBy...` and `queryBy...`\n\n`getBy...` will throw an `Error` if it didn't find queried element. `queryBy...` will return `null` instead.\n\nUsually it's better to use `getBy...` to have a nice error messages in Jest's output, but occasionally assertions using `queryBy...` will be easier to read.\n\n## Test accessibility\n\nNot all of accessibility testing of a web application can be automated, but much of it can be using¬†[jest-axe](https://github.com/nickcolley/jest-axe).\n\n```tsx\nimport \"jest-axe/extend-expect\";\nimport * as React from \"react\";\nimport { render } from \"@testing-library/react\";\nimport { axe } from \"jest-axe\";\n\ntest(\"inaccessible forms fail axe\", async () =\u003e {\n  const { container } = render(\u003cInaccessibleForm /\u003e);\n  const axeResult = await axe(container);\n  expect(() =\u003e expect(axeResult).toHaveNoViolations()).toThrow();\n});\n\ntest(\"accessible forms pass axe\", async () =\u003e {\n  const { container } = render(\u003cAccessibleForm /\u003e);\n  expect(await axe(container)).toHaveNoViolations();\n});\n```\n\n## Test `componentDidCatch` Error Boundary handler\n\n```tsx\nimport * as React from \"react\";\nimport { render } from \"@testing-library/react\";\nimport { reportError } from \"../api\";\nimport { ErrorBoundary } from \"../error-boundary\";\n\njest.mock(\"../api\");\n\nafterEach(() =\u003e {\n  jest.clearAllMocks();\n});\n\nfunction Bomb({ shouldThrow }) {\n  if (shouldThrow) {\n    throw new Error(\"üí£\");\n  } else {\n    return null;\n  }\n}\n\ntest(\"calls reportError and renders that there was a problem\", () =\u003e {\n  reportError.mockResolvedValueOnce({ success: true });\n  const { rerender } = render(\n    \u003cErrorBoundary\u003e\n      \u003cBomb /\u003e\n    \u003c/ErrorBoundary\u003e,\n  );\n\n  rerender(\n    \u003cErrorBoundary\u003e\n      \u003cBomb shouldThrow={true} /\u003e\n    \u003c/ErrorBoundary\u003e,\n  );\n\n  const error = expect.any(Error);\n  const info = { componentStack: expect.stringContaining(\"Bomb\") };\n  expect(reportError).toHaveBeenCalledWith(error, info);\n  expect(reportError).toHaveBeenCalledTimes(1);\n\n  expect(console.error).toHaveBeenCalledTimes(2);\n});\n```\n\nIt's possible to suppress `console.error` from the Error Boundary component. Useful for omitting the `console.error` messages in test results, if the formers make the latters messy.\n\n```tsx\nbeforeEach(() =\u003e {\n  jest.spyOn(console, \"error\").mockImplementation(() =\u003e {});\n});\n\nafterEach(() =\u003e {\n  console.error.mockRestore();\n});\n```\n\n### Ensure Error Boundaries can successfully recover from Errors\n\nThanks to `.mockClear()` we can _reset_ how many times the fn was called:\n\n```tsx\ntest(\"calls reportError and renders that there was a problem, then recovers from \", () =\u003e {\n  /* ... */\n\n  // here we are clearing out the mocks\n  console.error.mockClear();\n  mockReportError.mockClear();\n\n  rerender(\n    \u003cErrorBoundary\u003e\n      \u003cBomb /\u003e\n    \u003c/ErrorBoundary\u003e,\n  );\n\n  userEvent.click(screen.getByText(/try again/i));\n\n  expect(mockReportError).not.toHaveBeenCalled();\n  expect(console.error).not.toHaveBeenCalled();\n  expect(screen.queryByRole(\"alert\")).not.toBeInTheDocument();\n  expect(screen.queryByText(/try again/i)).not.toBeInTheDocument();\n});\n```\n\n## Mock `react-transition-group`\n\nGiven the Component:\n\n```tsx\n// hidden-message.tsx\nimport * as React from \"react\";\nimport { CSSTransition } from \"react-transition-group\";\n\nfunction Fade(props) {\n  return (\n    \u003cCSSTransition unmountOnExit timeout={1000} classNames=\"fade\" {...props} /\u003e\n  );\n}\n\nfunction HiddenMessage({ children }) {\n  const [show, setShow] = React.useState(false);\n  const toggle = () =\u003e setShow((s) =\u003e !s);\n  return (\n    \u003cdiv\u003e\n      \u003cbutton onClick={toggle}\u003eToggle\u003c/button\u003e\n      \u003cFade in={show}\u003e\n        \u003cdiv\u003e{children}\u003c/div\u003e\n      \u003c/Fade\u003e\n    \u003c/div\u003e\n  );\n}\n\nexport { HiddenMessage };\n```\n\nIn the case of `react-transition-group`, we don‚Äôt want to have to wait `1000ms` until the transition has completed before we can go on with our tests. We can mock `react-transition-group` implementation to do so:\n\n```tsx\nimport * as React from \"react\";\nimport { render, screen } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { HiddenMessage } from \"../hidden-message\";\n\njest.mock(\"react-transition-group\", () =\u003e {\n  return {\n    CSSTransition: (props) =\u003e (props.in ? props.children : null),\n  };\n});\n\ntest(\"shows hidden message when toggle is clicked\", () =\u003e {\n  const myMessage = \"hello world\";\n  render(\u003cHiddenMessage\u003e{myMessage}\u003c/HiddenMessage\u003e);\n  const toggleButton = screen.getByText(/toggle/i);\n  expect(screen.queryByText(myMessage)).not.toBeInTheDocument();\n  userEvent.click(toggleButton);\n  expect(screen.getByText(myMessage)).toBeInTheDocument();\n  userEvent.click(toggleButton);\n  expect(screen.queryByText(myMessage)).not.toBeInTheDocument();\n});\n```\n\nWhen we mock something, we want to make the mock as close to original function as possible.\n\n## Wrappers\n\nWrappers are a nice to have to avoid code repetition:\n\n```tsx\ntest(\"calls reportError and renders that there was a problem\", () =\u003e {\n  // [...]\n  const { rerender } = render(\u003cBomb /\u003e, { wrapper: ErrorBoundary });\n  // [...]\n});\n```\n\n## Mock HTTP with `jest.mock`\n\nIf we have a component that makes HTTP request we want to mock those out for UI unit and integration tests:\n\n```tsx\n// greeting-loader.tsx\n\nimport * as React from \"react\";\nimport { loadGreeting } from \"./api\";\n\nfunction GreetingLoader() {\n  const [greeting, setGreeting] = React.useState\u003cstring\u003e(\"\");\n  async function loadGreetingForInput(e) {\n    e.preventDefault();\n    const { data }: { data: { greeting: string } } = await loadGreeting(\n      e.target.elements.name.value,\n    );\n    setGreeting(data.greeting);\n  }\n  return (\n    \u003cform onSubmit={loadGreetingForInput}\u003e\n      \u003clabel htmlFor=\"name\"\u003eName\u003c/label\u003e\n      \u003cinput id=\"name\" /\u003e\n      \u003cbutton type=\"submit\"\u003eLoad Greeting\u003c/button\u003e\n      \u003cdiv aria-label=\"greeting\"\u003e{greeting}\u003c/div\u003e\n    \u003c/form\u003e\n  );\n}\n\nexport { GreetingLoader };\n```\n\n```tsx\n// greeting-loader.test.ts\n\nimport * as React from \"react\";\nimport { render, screen, waitFor } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { loadGreeting } from \"../api\";\nimport { GreetingLoader } from \"../greeting-loader\";\n\njest.mock(\"../api\");\n\ntest(\"loads greetings on click\", async () =\u003e {\n  const testGreeting = \"TEST_GREETING\";\n  loadGreeting.mockResolvedValueOnce({ data: { greeting: testGreeting } });\n  render(\u003cGreetingLoader /\u003e);\n\n  const nameInput = screen.getByLabelText(/name/i);\n  const loadButton = screen.getByText(/load/i);\n\n  await userEvent.type(nameInput, \"Mary\");\n  await userEvent.click(loadButton);\n\n  expect(loadGreeting).toHaveBeenCalledWith(\"Mary\");\n  expect(loadGreeting).toHaveBeenCalledTimes(1);\n\n  // waitFor uses `act()` for state updates for us\n  await waitFor(() =\u003e\n    expect(screen.getByLabelText(/greeting/i)).toHaveTextContent(testGreeting),\n  );\n});\n```\n\n## Mocking HTTP with `msw`\n\nIt would be nice addition to make sure that the API module is working properly when testing the components that are interacting with that module.\n\nThat would require us to actually interact with the API, but the requests would be intercepted. To intercept requests we need to setup the `msw` server intercepting them first.\n\nAlso, because the tests are ran in Node.js environment we need to polyfill the `fetch` module with `whatwg-fetch`.\n\n```tsx\nimport \"whatwg-fetch\";\nimport * as React from \"react\";\nimport { render, screen, waitFor } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { rest } from \"msw\";\nimport { setupServer } from \"msw/node\";\nimport { GreetingLoader } from \"../greeting-loader-01-mocking\";\n\nconst server = setupServer(\n  rest.post(\"/greeting\", (req, res, ctx) =\u003e {\n    return res(ctx.json({ data: { greeting: `Hello ${req.body.subject}` } }));\n  }),\n);\n\nbeforeAll(() =\u003e server.listen({ onUnhandledRequest: \"error\" })); // start the server\nafterAll(() =\u003e server.close());\nafterEach(() =\u003e server.resetHandlers());\n\ntest(\"loads greetings on click\", async () =\u003e {\n  render(\u003cGreetingLoader /\u003e);\n  const nameInput = screen.getByLabelText(/name/i);\n  const loadButton = screen.getByText(/load/i);\n\n  await userEvent.type(nameInput, \"Mary\");\n  await userEvent.click(loadButton);\n  await waitFor(() =\u003e\n    expect(screen.getByLabelText(/greeting/i)).toHaveTextContent(\"Hello Mary\"),\n  );\n});\n```\n\nThe cool part is that if we were to make some sort of mistake, not just in our component, but also in our client request, then we would catch that with this arguably simpler test. We also get a higher coverage.\n\n## Custom `renderComponent` fns to simplify tests\n\nHaving a custom `render[Component]` fn allows to simplify the test code:\n\n```tsx\nfunction renderEditor() {\n  const fakeUser = userBuilder()\n  const utils = render(\u003cEditor user={fakeUser} /\u003e)\n  const fakePost = postBuilder()\n\n  screen.getByLabelText(/title/i).value = fakePost.title\n  screen.getByLabelText(/content/i).value = fakePost.content\n  screen.getByLabelText(/tags/i).value = fakePost.tags.join(', ')\n  const submitButton = screen.getByText(/submit/i)\n  return {\n    ...utils,\n    submitButton,\n    fakeUser,\n    fakePost,\n  }\n}\n\ntest('renders a form with title, content, tags, and a submit button', async () =\u003e {\n  const {submitButton, fakePost, fakeUser} = renderEditor()\n    /* [...] */\n}\n```\n\n## Custom `history` implementation within `react-router`\n\nMocking the¬†`\u003cRedirect /\u003e`¬†component in `react-router` works, but it‚Äôs imperfect because we don‚Äôt know for sure that the user will be redirected properly.\n\nNormally we'd import `BrowserRouter`, but in tests we import `MemoryRouter` so we can manually control the `history` object.\n\n```tsx\nimport * as React from \"react\";\nimport { MemoryRouter } from \"react-router-dom\";\nimport { render as rtlRender, screen } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { Main } from \"../main\";\n\nfunction render(ui, { route = \"/\", ...renderOptions } = {}) {\n  function Wrapper({ children }) {\n    return \u003cMemoryRouter initialEntries={[route]}\u003e{children}\u003c/MemoryRouter\u003e;\n  }\n  return rtlRender(ui, {\n    wrapper: Wrapper,\n    ...renderOptions,\n  });\n}\n\ntest(\"main renders about and home and I can navigate to those pages\", async () =\u003e {\n  render(\u003cMain /\u003e);\n  expect(screen.getByRole(\"heading\")).toHaveTextContent(/home/i);\n  await userEvent.click(screen.getByText(/about/i));\n  expect(screen.getByRole(\"heading\")).toHaveTextContent(/about/i);\n});\n\ntest(\"landing on a bad page shows no match component\", () =\u003e {\n  render(\u003cMain /\u003e, {\n    route: \"/something-that-does-not-match\",\n  });\n  expect(screen.getByRole(\"heading\")).toHaveTextContent(/404/i);\n});\n```\n\n## Testing the unmounting of the component\n\nLet's assume we have the `Countdown` function component that will cleanup in `useEffect`/`useLayoutEffect`/`componentWillUnmount`.\n\n\u003e [!tip] `testing-library` doesn't care about component type\n\u003e\n\u003e The test case can be the same for both class and function components.\n\n```tsx\nimport { useEffect, useRef, useState } from \"react\";\n\nfunction Countdown() {\n  const [remainingTime, setRemainingTime] = useState(10000);\n  const end = useRef(new Date().getTime() + remainingTime);\n  useEffect(() =\u003e {\n    const interval = setInterval(() =\u003e {\n      const newRemainingTime = end.current - new Date().getTime();\n      if (newRemainingTime \u003c= 0) {\n        clearInterval(interval);\n        setRemainingTime(0);\n      } else {\n        setRemainingTime(newRemainingTime);\n      }\n    });\n    return () =\u003e clearInterval(interval);\n  }, []);\n  return remainingTime;\n}\n\nexport { Countdown };\n```\n\n```tsx\n// countdown.test.tsx\nimport * as React from \"react\";\nimport { render, act } from \"@testing-library/react\";\nimport { Countdown } from \"../countdown\";\n\n// keeping `console.error` out of the way in test output\nbeforeAll(() =\u003e {\n  jest.spyOn(console, \"error\").mockImplementation(() =\u003e {});\n});\n\nafterAll(() =\u003e {\n  console.error.mockRestore();\n});\n\nafterEach(() =\u003e {\n  jest.clearAllMocks();\n  jest.useRealTimers(); // this re-enables normal intervals/timers so the other tests can use them. just in case.\n});\n\ntest(\"does not attempt to set state when unmounted (to prevent memory leaks)\", () =\u003e {\n  jest.useFakeTimers();\n  const { unmount } = render(\u003cCountdown /\u003e);\n  unmount();\n  act(() =\u003e jest.runOnlyPendingTimers());\n  expect(console.error).not.toHaveBeenCalled();\n});\n```\n\nTo simulate unmounting the component, we're using `unmount` from `render` fn.\n\nTo make sure every intervals were cleared properly, we can use `\n`jest.useFakeTimers()`and`jest.runOnlyPendingTimers()`. The former will make sure the timers will run way quicker.\n\nAfter umnounting, we're calling `jest.runOnlyPendingTimers()` to see if there were any non-cleared intervals (we need to wrap it in `act`). 8\n\nWithout proper cleanup in the component, the error would be thrown here (that's why we're expecting errors not to be thrown).\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/testing-hooks":{"title":"Testing custom React hooks","content":"Given the hook:\n\n```tsx\n// useCounter.ts\nimport * as React from \"react\";\n\nfunction useCounter({ initialCount = 0, step = 1 } = {}) {\n  const [count, setCount] = React.useState(initialCount);\n  const increment = () =\u003e setCount((c) =\u003e c + step);\n  const decrement = () =\u003e setCount((c) =\u003e c - step);\n  return { count, increment, decrement };\n}\n\nexport { useCounter };\n```\n\nWe need to make sure we're using the hook inside the function component and wrap the hook fn call in an `act` fn, as a callback:\n\n```tsx\n// useCounter.test.tsx\nimport * as React from \"react\";\nimport { render, act } from \"@testing-library/react\";\nimport { useCounter } from \"../use-counter\";\n\ntest(\"exposes the count and increment/decrement functions\", () =\u003e {\n  let result;\n\n  function TestComponent() {\n    result = useCounter();\n    return null;\n  }\n\n  render(\u003cTestComponent /\u003e);\n\n  expect(result.count).toBe(0);\n  act(() =\u003e result.increment());\n  expect(result.count).toBe(1);\n  act(() =\u003e result.decrement());\n  expect(result.count).toBe(0);\n});\n```\n\n\u003e [!tip] Normally you don't need `act` for using Testing Library.\n\u003e\n\u003e All the internal functions are using `act` in their implementation if necessary.\n\n## Using `renderHook`\n\nWe could create a custom `setup` fn to reduce code duplication, but it'd a bit troublesome. Thankfully, there's a `renderHook` fn available in `@testing-library/react` that does exactly that:\n\n```tsx\nimport { renderHook, act } from \"@testing-library/react-hooks\";\nimport { useCounter } from \"../use-counter\";\n\ntest(\"exposes the count and increment/decrement functions\", () =\u003e {\n  const { result } = renderHook(useCounter);\n  expect(result.current.count).toBe(0);\n  act(() =\u003e result.current.increment());\n  expect(result.current.count).toBe(1);\n  act(() =\u003e result.current.decrement());\n  expect(result.current.count).toBe(0);\n});\n\ntest(\"allows customization of the initial count\", () =\u003e {\n  const { result } = renderHook(useCounter, {\n    initialProps: { initialCount: 3 },\n  });\n  expect(result.current.count).toBe(3);\n});\n\ntest(\"allows customization of the step\", () =\u003e {\n  const { result } = renderHook(useCounter, { initialProps: { step: 2 } });\n  expect(result.current.count).toBe(0);\n  act(() =\u003e result.current.increment());\n  expect(result.current.count).toBe(2);\n  act(() =\u003e result.current.decrement());\n  expect(result.current.count).toBe(0);\n});\n```\n\n## Testing the updates of custom React hooks if their props change over time\n\nJust use `rerender` fn:\n\n```tsx\ntest(\"the step can be changed\", () =\u003e {\n  const { result, rerender } = renderHook(useCounter, {\n    initialProps: { step: 3 },\n  });\n  expect(result.current.count).toBe(0);\n  act(() =\u003e result.current.increment());\n  expect(result.current.count).toBe(3);\n  rerender({ step: 2 });\n  act(() =\u003e result.current.decrement());\n  expect(result.current.count).toBe(1);\n});\n```\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/testing-portals":{"title":"Testing React portals","content":"\nGiven that we have a simple Modal component:\n\n```ts\nimport { useRef, useLayoutEffect } from \"react\";\nimport { createPortal } from \"react-dom\";\n\nlet modalRoot = document.getElementById(\"modal-root\");\nif (!modalRoot) {\n  modalRoot = document.createElement(\"div\");\n  modalRoot.setAttribute(\"id\", \"modal-root\");\n  document.body.appendChild(modalRoot);\n}\n\nfunction Modal({ children }): ReactElement {\n  const el = useRef(document.createElement(\"div\"));\n  useLayoutEffect(() =\u003e {\n    const currentEl = el.current;\n    modalRoot.appendChild(currentEl);\n    return () =\u003e modalRoot.removeChild(currentEl);\n  }, []);\n  return createPortal(children, el.current);\n}\n\nexport { Modal };\n```\n\nWe can test if `Modal` shows the `children` like that:\n\n```tsx\nimport * as React from \"react\";\nimport { render, within } from \"@testing-library/react\";\nimport { Modal } from \"../modal\";\n\ntest(\"modal shows the children\", () =\u003e {\n  render(\n    \u003cModal\u003e\n      \u003cdiv data-testid=\"test\" /\u003e\n    \u003c/Modal\u003e,\n  );\n  const { getByTestId } = within(document.getElementById(\"modal-root\"));\n  expect(getByTestId(\"test\")).toBeInTheDocument();\n});\n```\n\nThe `getByTestId` by default is bound to `document.body`, so it's available everywhere. Using `within` allows us to scope `getByTestId` down to the particular DOM node.\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/jest/testing-redux":{"title":"Testing Redux","content":"## Redux store setup\n\nWe have the code to be tested as follows:\n\n```tsx\n// redux-reducer.tsx\nconst initialState = { count: 0 };\n\nconst reducer = (state = initialState, action) =\u003e {\n  switch (action.type) {\n    case \"INCREMENT\":\n      return {\n        count: state.count + 1,\n      };\n    case \"DECREMENT\":\n      return {\n        count: state.count - 1,\n      };\n    default:\n      return state;\n  }\n};\n\nexport { reducer };\n```\n\n```tsx\n// redux-store.tsx\nimport { configureStore } from \"@reduxjs/toolkit\";\nimport { reducer } from \"./redux-reducer\";\n\nconst store = configureStore({ reducer });\n\nexport { store };\n```\n\n```tsx\n// redux-counter.tsx\nimport * as React from \"react\";\nimport { useSelector, useDispatch } from \"react-redux\";\n\nfunction Counter() {\n  const count = useSelector((state) =\u003e state.count);\n  const dispatch = useDispatch();\n  const increment = () =\u003e dispatch({ type: \"INCREMENT\" });\n  const decrement = () =\u003e dispatch({ type: \"DECREMENT\" });\n  return (\n    \u003cdiv\u003e\n      \u003ch2\u003eCounter\u003c/h2\u003e\n      \u003cdiv\u003e\n        \u003cbutton onClick={decrement}\u003e-\u003c/button\u003e\n        \u003cspan aria-label=\"count\"\u003e{count}\u003c/span\u003e\n        \u003cbutton onClick={increment}\u003e+\u003c/button\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n\nexport { Counter };\n```\n\n## Testing Redux Connected components\n\nWe need to wrap the component in `Provider` with a store associated with it:\n\n```tsx\nimport * as React from \"react\";\nimport { Provider } from \"react-redux\";\nimport { render, screen } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { Counter } from \"../redux-counter\";\nimport { store } from \"../redux-store\";\n\ntest(\"can render with `redux` with defaults\", async () =\u003e {\n  render(\n    \u003cProvider store={store}\u003e\n      \u003cCounter /\u003e\n    \u003c/Provider\u003e,\n  );\n  await userEvent.click(screen.getByText(\"+\"));\n  expect(screen.getByLabelText(/count/i)).toHaveTextContent(\"1\");\n});\n\ntest(\"can render with redux with custom initial state\", async () =\u003e {\n  const customInitialStateStore = configureStore({\n    reducer,\n    preloadedState: { count: 3 },\n  });\n  render(\n    \u003cProvider store={customInitialStateStore}\u003e\n      \u003cCounter /\u003e\n    \u003c/Provider\u003e,\n  );\n  await userEvent.click(screen.getByText(\"-\"));\n  expect(screen.getByLabelText(/count/i)).toHaveTextContent(\"2\");\n});\n```\n\nThe cool part is that we're testing our application store as well as the component that's using this store, in integration.\n\nIn tests themselves, we only interact with the component itself, as it is not using Redux at all (redux as an implementation detail), so if we were to migrate away from Redux to some other state management solution, we would need minimum updates to our tests.\n\nIt's also useful to create a custom render function for testing:\n\n```tsx\nimport * as React from \"react\";\nimport { configureStore } from \"@reduxjs/toolkit\";\nimport { Provider } from \"react-redux\";\nimport { render as rtlRender, screen } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { Counter } from \"../redux-counter\";\nimport { reducer } from \"../redux-reducer\";\n\nfunction render(\n  ui,\n  {\n    initialState,\n    store = configureStore({ reducer, preloadedState: initialState }),\n    ...renderOptions\n  } = {},\n) {\n  function Wrapper({ children }) {\n    return \u003cProvider store={store}\u003e{children}\u003c/Provider\u003e;\n  }\n  return {\n    ...rtlRender(ui, {\n      wrapper: Wrapper,\n      ...renderOptions,\n    }),\n    store,\n  };\n}\n\ntest(\"can increment the value\", async () =\u003e {\n  render(\u003cCounter /\u003e);\n  await userEvent.click(screen.getByText(\"+\"));\n  expect(screen.getByLabelText(/count/i)).toHaveTextContent(\"1\");\n});\n\ntest(\"can decrement the value\", async () =\u003e {\n  render(\u003cCounter /\u003e, {\n    initialState: { count: 3 },\n  });\n  await userEvent.click(screen.getByText(\"-\"));\n  expect(screen.getByLabelText(/count/i)).toHaveTextContent(\"2\");\n});\n```\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/mocking":{"title":"Mocking","content":"\nMocking is used to enable testing modules that depend (as in _dependency_) on another modules, that we don't want to _really_ use, e.g. credit card service.\n\nWe may not want to do any requests with a credit card service, so we can mock it (btw making its behavior [[deterministic]]).\n\n## Monkey patching\n\nMonkey patching is the most naive (and limited) approach to mocking in JS. Basically it's overriding an object property (e.g. `utils.getWinner()`) in the test.\n\n```ts\nconst assert = require(\"assert\");\nconst thumbWawr = require(\"../thumbwar\");\nconst utils = require(\"../utils\"); // `utils` is the module we want to mock\n\nconst originalGetWinner = utils.getWinner; // saving the original implementation for cleanup\nutils.getWinner = (p1, p2) =\u003e p1; // here we make sure `.getWinner` will always ensure the first player wins\n\nconst winner = thumbWar(\"Kent C. Dodds\", \"Ken Wheeler\");\nassert.strictEqual(winner, \"Kent C. Dodds\"); // PASS\n\nutils.getWinner = originalGetWinner; // cleanup\n```\n\n\u003e [!danger] In ES modules monkey patching does not work.\n\n### Cleanup\n\nImportant thing in testing is to clean up after the mocking in the test case, so the other cases may use the original module again or mock it in a different way.\n\nIn this test case we reassign the real function, exported from the `utils.ts` back to `getWinner`.\n\n## Ensuring fns are called properly with mocks\n\nWhen writing tests and mocking dependencies, we want to verify that the function was called correctly, by tracking how often the function was called and what arguments it was called with. This is to ensure the usage of `utils.getWinner` in `thumbWar` implementation is correct.\n\nTo do that we may use `jest.fn` _mock function_. It keeps track the parameters and how many it was called.\n\n```ts\nutils.getWinner = jest.fn((p1, p2) =\u003e p1);\n\nexpect(utils.getWinner).toHaveBeenCalledTimes(2);\nexpect(utils.getWinner).toHaveBeenCalledWith(\"Kent C. Dodds\", \"Ken Wheeler\");\nexpect(utils.getWinner).toHaveBeenNthCalledWith(\n  1,\n  \"Kent C. Dodds\",\n  \"Ken Wheeler\",\n);\nexpect(utils.getWinner).toHaveBeenNthCalledWith(\n  2,\n  \"Kent C. Dodds\",\n  \"Ken Wheeler\",\n);\n```\n\n## `jest.fn`\n\n`jest.fn` internally is a function that has some nice properties for use:\n\n- `mock`\n  - `calls` - an array that holds all of the args that the function was called with\n\nLast 3 assertions could be rewritten as one:\n\n```ts\nexpect(utils.getWinner.mock.calls).toEqual([\n  [\"Kent C. Dodds\", \"Ken Wheeler\"],\n  [\"Kent C. Dodds\", \"Ken Wheeler\"],\n]);\n```\n\nThis could be implemented this way:\n\n```ts\ntype MockFnType = { mock: { calls: any[] } };\n\nfunction fn(impl) {\n  const mockFn: MockFnType = (...args) =\u003e {\n    mockFn.mock.calls.push(args);\n    return impl(args);\n  };\n  mockFn.mock = { calls: [] }; // this implementation saves each call in the array\n  return mockFn;\n}\n\n// usage\nutils.getWinner = fn((p1, p2) =\u003e p1);\n```\n\n## `jest.spyOn`\n\nWe can use `jest.spyOn` to avoid keeping track of the original implementation (`const originalGetWinner = utils.getWinner`) and cleaning up after the test case (`utils.getWinner = originalGetWinner`) on our own.\n\n```ts\njest.spyOn(utils, \"getWinner\"); // spying on the original implementation\nutils.getWinner.mockImplementation((p1, p2) =\u003e p2);\n\nutils.getWinner.mockRestore(); // cleanup\n```\n\nThis could be implemented this way:\n\n```ts\ntype MockFnType = {\n  mock: { calls: any[] };\n  mockImplementation: (any) =\u003e any;\n};\n\nfunction fn(impl = (args: any[]) =\u003e {}) {\n  const mockFn: MockFnType = (...args: any[]) =\u003e {\n    mockFn.mock.calls.push(args);\n    return impl(args);\n  };\n  mockFn.mock = { calls: [] };\n  mockFn.mockImplementation = (newImpl) =\u003e (impl = newImpl); // saving the mocked implementation\n  return mockFn;\n}\n\nfunction spyOn(obj: any, property: string) {\n  const originalProperty = obj[property]; // track original value, function\n\n  obj[property] = fn();\n  obj[property].mockRestore = () =\u003e (obj[property] = originalProperty); // adding a way to \"release the mock\"\n}\n```\n\nUp to this point we still were doing something only just slightly more sophisticated to [[course-notes/testing-javascript/mocking#Monkey patching|monkey patching]]. It works only because we're using CommonJS. In ES modules monkey patching does not work.\n\n## `jest.mock`\n\n`jest.mock` returns a mocked implementation of a whole module.\n\n```ts\njest.mock('../utils', () =\u003e { // first arg: relative path to the mocked module\n  // second arg: module factory function\n  return {\n      getWinner: jest.fn((p1, p2) =\u003e p1);\n  }\n});\n\n// cleanup\nutils.getWinner.mockReset();\n```\n\n`.mockReset()` will¬†reset our mock function to the initial state clearing out the `calls`.\n\n`jest.mock` works, because Jest is in control of the whole module system.\n\n\u003e [!tip] Jest hoists the `jest.mock` call to the top of the file, before imports.\n\u003e\n\u003e We don't have to do it manually.\n\nThis is how we can implement it on our own by using `require.cache`.\n\n```ts\nconst utilsPath = require.resolve(\"../utils\");\n\ntype MockFnType = {\n  mock: { calls: any[] };\n  mockImplementation: (any) =\u003e any;\n};\n\nfunction fn(impl = (...args: any[]) =\u003e {}) {\n  const mockFn: MockFnType = (...args: any[]) =\u003e {\n    mockFn.mock.calls.push(args);\n    return impl(...args);\n  };\n  mockFn.mock = { calls: [] };\n  mockFn.mockImplementation = (newImpl) =\u003e (impl = newImpl);\n  return mockFn;\n}\n\n// @ts-ignore missing properties\nrequire.cache[utilsPath] = {\n  id: utilsPath,\n  filename: utilsPath,\n  loaded: true,\n  exports: {\n    getWinner: fn((p1, p2) =\u003e p1),\n  },\n};\n\ndelete require.cache[utilsPath]; // cleanup\n```\n\nThis is something similar, yet simplified version of what Jest is doing.\n\n## Mocking a module shared across the codebase\n\nUse `__mocks__` directory.\n\n```sh\n$ tree\n‚îú‚îÄ‚îÄ __mocks__\n‚îÇ   ‚îî‚îÄ‚îÄ utils.ts\n‚îî‚îÄ‚îÄ utils.ts\n```\n\nThen in test file:\n\n```ts\njest.mock(\"../utils\");\n```\n\n`jest` knows to pick up the path from __mocks__ directory. \n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null},"/development/testing-javascript/static-analysis":{"title":"Static Analysis","content":"\n*Static analysis*¬†is a method of debugging that is done by automatically examining the source code **without having to execute the program** with tools like `eslint`, `prettier`, `typescript`, `husky`.\n\n## ESLint\n\n- use `ESLint` extension (by Dirk Baeumer) for VS Code\n  - `‚åò + .`¬†provides hints on how to fix the issues\n- `eslint` provides a set of recommended rules that can be _extended_:\n\n```json\n// .eslintrc\n{\n  \"extends\": [\"eslint:recommended\" /* another extension */],\n  \"rules\": {\n    // overrides to extended configurations\n  }\n}\n```\n\n- instead of using `.eslintignore` which is oftenly exactly the same as `.gitignore`, add the flag to `npm script` :\n  - `eslint --ignore-path .gitignore .`\n\n## Prettier\n\n- `--ignore-path .gitignore` is supported in Prettier as well\n- there's a Prettier [Playground](https://prettier.io/playground) in which we can experiment with the configuration and save it to `.prettierrc`\n- use Prettier extension (by Esben Petersen) for VSCode with these options:\n  - `editor.defaultFormatter: \"esbenp.prettier-vscode\"`\n  - `editor.formatOnSave: true`\n- disable unnecessary ESLint rules with `eslint-config-prettier` extension to make sure Prettier and ESLint won't clash\n- `prettier` has a `--list-different` flag used when you want to throw an `Error` if the formatting sucks\n\n## `yarn`\n\n```json\n{\n  \"scripts\": {\n    \"prettier\": \"prettier --ignore-path .gitignore \",\n    \"format\": \"npm run prettier -- --write\"\n    /** \n    `--` makes yarn to use the parameters of \n    `prettier` script without rewriting them \n    effectively making the `format` script: \n    \n    \"format\": \"prettier --ignore-path .gitignore --write\" */\n  }\n}\n```\n\n## TypeScript tips\n\n- **use TypeScript**, at least for types analysis (if you can't for compiling for some reason)\n- use `@typescript-eslint/eslint-plugin` and `@typescript-eslint/parser` for `*.ts(x)` files\n\n## Husky\n\n- use `precommit` hooks to statically analyze the codebase\n- Husky can be integrated with `lint-staged` for those who don't use editor with Prettier/ESLint plugins\n\n## `npm-run-all`\n\n`npm-run-all` is a tool that allows to run `npm` scripts in parallel:\n\n```json\n{\n  \"scripts\": {\n    \"build\": \"/* ... */\",\n    \"check-format\": \"/* ... */\",\n    \"check-types\": \"/* ... */\",\n    \"lint\": \"/* ... */\",\n    \"validate\": \"npm-run-all check-types check-format lint build\" // \u003c--\n  }\n}\n```\n","lastmodified":"2022-12-30T17:27:27.240993142Z","tags":null}}